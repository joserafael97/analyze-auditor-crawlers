---
title: "REPLACE ME"
output:
    html_document:
    df_print: paged
theme: sandstone
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse) # 
library(jsonlite) # Ler dados json
library(dplyr) # 
library(here)
library(ggplot2)
source(here::here("code/lib.R"))
theme_set(theme_bw())
```

## Lendo os dados

```{r read}
resultados_avaliacoes = read_avaliacoes()
resultados_avaliacoes[is.na(resultados_avaliacoes)] <- ""

gararito = read_gabaritos()
gararito[is.na(gararito)] <- ""

empresas_portais <- readr::read_csv(here::here("data/empresas_portais.csv"))
```


## Adicionando Combinação identificada no portal em cada Município no gabarito

```{r}
empresas_portais <- empresas_portais %>% 
    select(municipio, fornecedor)

gararito<-left_join(gararito, empresas_portais, by=c("municipio"))
```


## Juntando Avaliações e Gabaritos

```{r}
# concatena os dois csv o do gabarito e avaliações do crawler
data<-full_join(resultados_avaliacoes, gararito, by=c("municipio", "item", "criterio"))
```



```{r}

precisao <- data %>% 
    group_by(municipio, criterio, item, aproach, date) %>% 
    mutate(
           
           #verifica se a avaliação foi acertiva
           tp = valid == TRUE 
           & valid == encontrado 
           #valida se no gabarito e na avaliação o item foi encontrado na mesma url 
           & (grepl(local_encontrado, pathSought) |
                  grepl(local_encontrado_2, pathSought)),
           
           fn =  valid == FALSE 
           & encontrado == TRUE,
           
           fp = valid == TRUE 
           & encontrado == FALSE
          )
```

Quantificando métricas

```{r}

metricas_result <- precisao %>% 
    #filter(!is.na(aproach )) %>% 
    group_by(municipio, aproach, date) %>% 
    summarise(
        tp_total = sum(tp), 
        fn_total = sum(fn),
        fp_total = sum(fp),
        
        #cálculo das métricas 
        recall = tp_total/(tp_total + fn_total),
        precision =  tp_total/(tp_total + fp_total),
        f1_score = (2*(recall*precision))/(recall+precision),
        
        #tempo das avaliações
        median_duration_min = median(durationMin),
        median_duration = median(duration),
        max_duration = max(duration),
        max_durationMin = max(durationMin),
        median_num_access_node = median(contNodeNumberAccess),
        max_num_access_node = max(contNodeNumberAccess),
        all_access_node = sum(contNodeNumberAccess),
        combination = last(fornecedor)

    )

metricas_result 

metricas_result$tp_total <- NULL
metricas_result$fp_total <- NULL
metricas_result$fn_total <- NULL
metricas_result$median_duration <- NULL
metricas_result$max_duration <- NULL

metricas_result %>%
    arrange(desc(recall)) 
```
```{r}
metricas_result %>%
    group_by(municipio) %>%
    summarise(bfs = sum(aproach == 'bfs'), dfs = sum(aproach == 'dfs'), bandit = sum(aproach == 'bandit')) %>%
    arrange(desc(bfs)) 
```


Vamos analisar onde ocorreu as divergências entre o gabarito e o resultado do crawler
bfs	2019-11-09 23:00:55	35	3	0	0.9210526	1.0000000	0.9589041

```{r}
metricas_result %>%
    ggplot() + 
    geom_point(aes(x=aproach, y=recall,  color=aproach), position = "jitter")  

metricas_result %>%
    ggplot() + 
    geom_point(aes(x=aproach, y=f1_score,  color=aproach), position = "jitter")  
```
```{r}
metricas_result %>%
    ggplot() + 
    geom_point(aes(x=aproach, y=median_duration_min,  color=aproach), position = "jitter")  

metricas_result %>%
    ggplot() + 
    geom_point(aes(x=aproach, y=max_durationMin,  color=aproach), position = "jitter")  
```
```{r}
metricas_result %>%
    ggplot() + 
    geom_point(aes(x=aproach, y=max_num_access_node,  color=aproach), position = "jitter")  
```



```{r}
precisao$contNodeNumberAccess <- NULL
precisao$duration <- NULL
precisao$durationMin <- NULL

precisao %>% 
    filter(municipio == "Coremas", valid == FALSE, encontrado == TRUE, criterio=="Despesa Orçamentária") %>% 
    arrange(desc(criterio))

```
