---
title: "REPLACE ME"
output:
    html_document:
    df_print: paged
theme: sandstone
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse) # 
library(jsonlite) # Ler dados json
library(dplyr) # 
library(here)
library(ggplot2)
source(here::here("code/lib.R"))
theme_set(theme_bw())
```

## Lendo os dados

```{r read}
resultados_avaliacoes = read_avaliacoes()
resultados_avaliacoes[is.na(resultados_avaliacoes)] <- ""

gararito = read_gabaritos()
gararito[is.na(gararito)] <- ""

data<-full_join(resultados_avaliacoes, gararito, by=c("municipio", "item", "criterio"))
empresas_portais <- readr::read_csv(here::here("data/empresas_portais.csv"))
fornecedores <- readr::read_csv(here::here("data/empresas.csv"))
```

##Combinações diferentes 

```{r}
empresas_portais[is.na(empresas_portais)] <- ""


empresas_portais %>%
    group_by(fornecedor) %>%
    summarise(num_municipios_atendidos = n()) %>%
    arrange(desc(num_municipios_atendidos))
    
```
Existem 48 combinações diferentes entre os fornecedores. A Publicsoft sozinha (Sem contar combinações) é a empresa que mais atende municípios (56) 

```{r}
fornecedores
```
Existem 23 empresas fornecedoras de portais de transparência na Paraíba.


```{r}

precisao <- data %>% 
    group_by(municipio, criterio, item, aproach, date) %>% 
    mutate(
           
           #verifica se a avaliação foi acertiva
           tp = valid == TRUE 
           & valid == encontrado 
           #valida se no gabarito e na avaliação o item foi encontrado na mesma url 
           & (grepl(local_encontrado, pathSought) |
                  grepl(local_encontrado_2, pathSought)),
           
           fn =  valid == FALSE 
           & encontrado == TRUE,
           
           fp = valid == TRUE 
           & encontrado == FALSE
          )
```

Quantificando métricas

```{r}

metricas_result <- precisao %>% 
    group_by(municipio, aproach, date) %>% 
    summarise(
        tp_total = sum(tp), 
        fn_total = sum(fn),
        fp_total = sum(fp),
        
        #cálculo das métricas 
        recall = tp_total/(tp_total + fn_total),
        precision =  tp_total/(tp_total + fp_total),
        f1_score = (2*(recall*precision))/(recall+precision),
        
        #tempo das avaliações
        median_duration_min = median(durationMin),
        median_duration = median(duration),
        max_duration = max(duration),
        max_durationMin = max(durationMin),
        median_num_access_node = median(contNodeNumberAccess),
        max_num_access_node = max(contNodeNumberAccess)
    )

metricas_result

metricas_result$tp_total <- NULL
metricas_result$fp_total <- NULL
metricas_result$fn_total <- NULL
metricas_result$median_duration <- NULL
metricas_result$max_duration <- NULL

metricas_result
```


Vamos analisar onde ocorreu as divergências entre o gabarito e o resultado do crawler


```{r}
 precisao %>% 
    group_by(criterio, municipio) %>%
    summarize(total_fn = sum(fn == TRUE), total_itens = n()) %>%
    ggplot() + 
    geom_bar(aes(x=criterio, y=total_fn), fill="#DD8888",stat="identity")+
    facet_grid(municipio ~ .)


precisao %>% 
    group_by(criterio, municipio) %>%
    summarize(total_fp = sum(fp == TRUE), total_itens = n()) %>%
    ggplot() + 
    geom_bar(aes(x=criterio, y=total_fp), fill="#DD8888",stat="identity") + 
    facet_grid(municipio ~ .)
```


```{r}
precisao %>% filter(municipio == "Arara", tp == FALSE, encontrado == TRUE) 

```


