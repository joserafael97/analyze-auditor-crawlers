---
title: "Experimento 01 Auditor Crawler"
output:
    html_document:
    css: styles.css
theme: sandstone
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse) # 
library(broom)
library(jsonlite) # Ler dados json
library(dplyr) # 
library(here)
library(DT)
library(boot)
library(ggalt)
set.seed(12345)
library(ggplot2)
library(ggbeeswarm)
source(here::here("code/lib.R"))
library(knitr)
library(kableExtra)
theme_set(theme_bw())
require(gridExtra)
```


## Problema 

A ausência de estratégias  de recuperação da informação eficientes e de caráter eficaz, com aplicação robusta no contexto da identificação e avaliação automática de critérios fiscais em portais de transparência municipais.

## Contexto

Com base no problema apresentado, este trabalho propôs a utilização e validação de crawlers para avaliar automaticamente portais municipais de transparência. Assim, durante a pesquisa foi implementado um crawler focado (crawlers aplicados a um contexto único) para avaliar os portais de transparência dos municipios do estado da Paraíba, utilizando como diretrizes de avaliação e validação da solução o Índice de transparência Municipal criado pelo Tribunal de Contas da Paraíba (TCE-PB). Por meio do ìndice foram elicitados itens para serem classificados como presentes ou ausentes em cada portal.

Neste contexto, com o objetivo de construir uma solução eficaz, eficiente e robusta foram experiementadas diferentes formas de buscar por novas páginas, partindo da premissa que o modo de percorrer e buscar novas páginas é tem impacto direto na manuteção destas métricas. Desta forma, foram avaliados 3 diferentes algoritmos neste aspaceto, sendo dois algoritmos tradicionais neste tipo de aplicação BFS e DFS e outro encontrado na litertatura o E-greedy.    

## Experimento 1 

Neste experimento foi avaliado o desempenho do crawler focado na avaliação da transparênica e a utilização dos Algoritmos BFS, DFS em relação ao Epsilon-greedy durante a busca e identificação dos critérios ficais nos sites de transparência. Este experimento tentar responder as seguintes perguntas:

1. Como se comporta o crawler em relação ao Recall e Precisão considerando os diferentes algoritmos durante as avaliações de transparência (Eficácia)?
2. Como se comporta o crawler em relação a número de nós acessados considerando os diferentes algoritmos durante as avaliações (Eficiência)?
3. Como é a estabilidade do crawler considerando cada um dos algoritmos e as combinação de portal de transparência?
4. Como se comporta a variação do crawler considerando os diferentes algoritmos e as combinações de transparência?


Para responder essas perguntas foram utilizadas as seguintes variáveis: 

* Recall de cada avaliação;
* Precisão de cada avaliação;
* Número máximo de nós acessados;
* Mediana do número de nós acessados;
* Duração máxima em minutos da avaliação;
* Mediana da duração da avaliação em minutos;
* Combinação de portais de transparência;

Obs: Um nó pode ser representado por um link ou componente clicável em páginas da web.


```{r warning=FALSE, include=FALSE}
resultados_avaliacoes_exp01 = read_avaliacoes()
resultados_avaliacoes_exp01[is.na(resultados_avaliacoes_exp01)] <- ''
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "bandit", "Epsilon-greedy")
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "bfs", "Bfs")
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "dfs", "Dfs")


gararito = read_gabaritos()
gararito[is.na(gararito)] <- ''

empresas_portais <- readr::read_csv(here::here("data/empresas_portais.csv"))
```


## Avaliações válidas

As avaliações válidas são excuções do Crawler que tiveram entre os critérios fiscais avaliados 61 itens pesquisados. Deste modo, para evitar ruídos que possam impactar nos resultados obtidos, todas as avaliações que não contínham este padrão de validade foram descartadas. Além disso, as avaliações do município de ***Curral de Cima*** não foram consideradas por seu portal de transparência está atualmente fora do ar, restando 29 municípios na amostra.


```{r warning=FALSE, include=FALSE}
resultados_avaliacoes_exp01 <- resultados_avaliacoes_exp01 %>% 
  filter(tipo_exp == 'all_itens' & (municipio != 'Curral de Cima' & municipio != 'todo'))

```



```{r warning=FALSE, include=FALSE}
empresas_portais <- empresas_portais %>% 
    select(municipio, fornecedor)

gararito<-left_join(gararito, empresas_portais, by=c("municipio"))
```


```{r warning=FALSE, include=FALSE}
# concatena os dois csv o do gabarito e avaliações do crawler
data<-left_join(resultados_avaliacoes_exp01, gararito, by=c("municipio", "item", "criterio"))
```

## Um exemplo dos dados utilizados


```{r echo=FALSE}

sumarise_exp01 <- data %>% 
    group_by(id, municipio, criterio, item, aproach, date) %>% 
    mutate(
           
           #verifica se a avaliação foi acertiva
           tp = (valid == TRUE 
           & valid == encontrado 
           #valida se no gabarito e na avaliação o item foi encontrado na mesma url 
           & (grepl(local_encontrado, pathSought) |
                  grepl(local_encontrado_2, pathSought))) | (valid == FALSE 
           & valid == encontrado),
           
           fn =  valid == FALSE 
           & encontrado == TRUE,
           
           fp = valid == TRUE 
           & encontrado == FALSE
          )




kable(head(sumarise_exp01 %>%
  select(municipio, criterio, item, aproach, tp, contNodeNumberAccess, durationMin))) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) 
```



## Quantificando métricas

Calculando Recall, Precision, F1 Score e métricas relacionadas ao desempenho do Auditor Crawler.

```{r warning=FALSE, include=FALSE}

metricas_result_exp01 <- sumarise_exp01 %>% 
    #filter(!is.na(aproach )) %>% 
    group_by(municipio, aproach, date) %>% 
    summarise(
        total_itens = n(),
        tp_total = sum(tp), 
        fn_total = sum(fn),
        fp_total = sum(fp),
        
        #cálculo das métricas 
        recall = tp_total/(tp_total + fn_total),
        precision =  tp_total/(tp_total + fp_total),
        f1_score = (2*(recall*precision))/(recall+precision),
        
        #tempo das avaliações
        median_duration_min = median(durationMin),
        median_duration = median(duration),
        max_duration = max(duration),
        max_durationMin = max(durationMin),
        median_num_access_node = median(contNodeNumberAccess),
        max_num_access_node = max(contNodeNumberAccess),
        all_access_node = sum(contNodeNumberAccess),
        combination = last(fornecedor),
        tipo_exp = last(tipo_exp)
    )


metricas_result_exp01 <- metricas_result_exp01 %>%
  filter(total_itens == 61  & recall > 0.46)

metricas_result_exp01 %>% 
    write_csv(here::here("data/resultados_sumarizado_exp01.csv"))

metricas_result_exp01 %>%
  arrange(desc(recall))

```


```{r warning=FALSE, include=FALSE}
metricas_result_exp01 <- metricas_result_exp01 %>%
  group_by(municipio, aproach) %>%
  mutate(variance_recall = sd(recall), recall_median = median(recall)) %>%
  ungroup() %>%
  mutate(recall_t = recall - recall_median ) %>%
  arrange(desc(recall_t), municipio, aproach) %>%
  group_by(municipio, aproach) %>%
  slice(seq_len(3)) %>%
  ungroup()
```

## Número de Avaliações por Algoritmo


```{r echo=FALSE}
metricas_result_exp01 %>%
    group_by(aproach) %>% 
    summarise(ocorrencia = n()) %>%
    ggplot(aes(y=ocorrencia, x=reorder(aproach, +(ocorrencia)))) + 
    geom_bar(stat = "identity",  fill="#5499C7") + 
    ggtitle("Número de Avaliações por Abordagem") +
    xlab("Abordagem") + 
    ylab("Número de avaliações") +
    coord_flip()
```

Foram coletadas entre os algoritmos 3 avaliações por portal de transparência. No total foram realizadas proporcionalmente 261 avalições dividas entre os 29 portais da amostra e os algoritmos de busca avaliados.

## Como se comporta o crawler em relação ao Recall e a Precisão considerando os diferentes algoritmos durante as avaliações de transparência (Eficácia)?

Para avaliar a eficácia do crawler com uso dos diferentes algoritmos propostos foram utilizadas a métricas de Recall e Precisão. A escolha destas métricas foi motivada pela necessidade do equilíbrio entre os valores obtidos para Recall e Precision, em outras palavras, da necessidade de uma avaliação de transparência que consiga identificar a maior quantidade de itens possível (Recall) e que mantenha uma alta confiabilidade nos itens identificados (Precision). 

### Recall das avaliações por algoritmo

A Figura x apresenta a distribuição e a mediana das avaliações entre os diferentes algoritmos de buscas experimentados. 


```{r echo=FALSE}
metricas_result_exp01 %>%
  group_by(aproach) %>%
  mutate(median_value = median(recall)) %>%
  ungroup() %>%
  ggplot(aes(x =  reorder(aproach, -(median_value)), y = recall)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 0.0115,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  ylim(0.5, 1) +
  labs(x='Algoritmo', y="Recall", color = "") + 
  theme(legend.position = "top")

ggsave('01-exp01-distribuition-recall.png')

```

Na Figura x é possível observar uma notável semelhança entre as distribuições do Recall nas avaliações para cada uma dos algoritmos, estando a maior parte das avaliações entre as faixas de valores de 0.7 até 1. Apesar disto, existem alguns outiles situados abaixo destas faixas de valores e encontrados nos resultados obtidos com os algoritmos Epsilon-greedy e Dfs. Estes fazem parte de avaliações pertecentes ao portal de transparência do município de Remígio, ao qual o crawler utilizando Epsilon-greedy ou DFs não consegue lidar com as sessões temporárias dentro de iframes de forma efetiva, devido o acesso não sequencial aos nós e a má prática no uso de iframes embutidos nas páginas neste site. Além disso, comparando as medianas entre os algoritmos é quase imperceptível a moderada diferença entre os métodos de busca, variando entre 0.90 (Epsilon-greedy) e 0.89 (Dfs e Bfs).


#### Intervalos de Confiança da mediana do Recall

Vamos criar intervalos de confiança para mediana de F1 Score para verificar se os intervalos contém a mediana da amostra entre as abordagens.

```{r include=FALSE}
#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

recall_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$recall)
    ))
}

create_ic.recall <- function(x) {
  x <- last(x)
  df.boot <- filter(metricas_result_exp01, aproach == x)
  
  bootstrap.aproach <- boot(
          data = df.boot, 
          statistic = recall_boot, 
          R = 4000 )
  
  ci = tidy(bootstrap.aproach, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


ics.aproach_exp01.recall <- metricas_result_exp01 %>%
  group_by(aproach) %>% 
   summarise(
     median_value = median(recall),
     ci = list(create_ic.recall(aproach))
  ) %>% 
  unnest(ci) 


```

#### IC Diferença Recall do Epsilon-greedy e Dfs

```{r echo=FALSE}
set.seed(123)

# IC entre DFs e E-greedy

diff_mediana_recall.e_greedy.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(e_greedy-dfs)
}

booted.dif <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_recall.e_greedy.dfs, 
               R = 4000)
ci.dif = tidy(booted.dif, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
glimpse(ci.dif)


p1.recall.e_greedy.dfs = ics.aproach_exp01.recall %>% 
  filter(aproach != 'Bfs') %>%  
  ggplot() + 
  geom_errorbar(aes(x =  reorder(aproach, -(median_value)), y = statistic, ymin = conf.low, ymax = conf.high), width = 0.05) +
  geom_point(aes(x=aproach, y=median_value), size=3) + 
  ylim(0.7, 1) +
  labs(x='Algoritmo', y="Recall", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 


p2.recall.e_greedy.dfs = ci.dif %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 3) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray")) +
  geom_hline(yintercept = -0.5, color="#B2B0AF",)

grid.arrange(p1.recall.e_greedy.dfs, p2.recall.e_greedy.dfs, nrow = 1)

```

#### IC Diferença Recall do Epsilon-greedy e Bfs

```{r}
# IC entre BFs e E-greedy

diff_mediana_recall.e_greedy.bfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  
  return(e_greedy-bfs)
}

booted.dif.recall.2 <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_recall.e_greedy.bfs, 
               R = 4000)

ci.dif.recall.greedy.bfs = tidy(booted.dif.recall.2, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.recall.greedy.bfs)

p1.recall.e_greedy.bfs = ics.aproach_exp01.recall %>% 
  filter(aproach != 'Dfs') %>%  
  ggplot() + 
  geom_errorbar(aes(x =  reorder(aproach, -(median_value)), y = statistic, ymin = conf.low, ymax = conf.high), width = 0.05) +
  geom_point(aes(x=aproach, y=median_value), size=3) + 
  ylim(0.7, 1) +
  labs(x='Algoritmo', y="Recall", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  


p2.recall.e_greedy.bfs = ci.dif.recall.greedy.bfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 3) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "Recall") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = -0.5, color="#B2B0AF",)


grid.arrange(p1.recall.e_greedy.bfs, p2.recall.e_greedy.bfs, nrow = 1)

```


### Precisão das avaliações por algoritmo


```{r echo=FALSE}
metricas_result_exp01 %>%
  group_by(aproach) %>%
  mutate(median_value = median(precision)) %>%
  ungroup() %>%
  ggplot(aes(x = reorder(aproach, -(median_value)), y = precision)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 0.0115,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  labs(x='Algoritmo', y="Precisão", title="", color = "") + 
  guides(fill=guide_legend(title="Algoritmo")) + 
  ylim(0.5, 1) +
  theme(legend.position = "top")

ggsave('exp01-distribuition-precision.png')
```



Com base na visualização é possível perceber que a abordagem Bandit apresenta a maior mediana. Além disso, é possível notar que a abordagem BFS é a única que não contém outlies.


De acordo com a visulização é verificar com 95% de confiança que a mediana da amostra para cada abordagem está contida nos intervalos.


#### Intervalos de Confiança da mediana de Precisão


```{r include=FALSE}
#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

precision_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$precision)
    ))
}

create_ic.precision <- function(x) {
  x <- last(x)
  df.boot <- filter(metricas_result_exp01, aproach == x)
  
  bootstrap.aproach.precision <- boot(
          data = df.boot, 
          statistic = precision_boot, 
          R = 4000 )
  
  ci = tidy(bootstrap.aproach.precision, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


ics.aproach_exp01.precision <- metricas_result_exp01 %>%
  group_by(aproach) %>% 
   summarise(
     median_value = median(precision),
     ci = list(create_ic.precision(aproach))
  ) %>% 
  unnest(ci) 

```

#### IC Diferença Precisão do Bfs e Dfs

```{r echo=FALSE}
set.seed(123)

# IC entre DFs e BFS

diff_mediana_precision.bfs.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(bfs-dfs)
}

booted.dif.preci.bfs.dfs <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_precision.bfs.dfs, 
               R = 4000)

ci.dif.preci.bfs.dfs = tidy(booted.dif.preci.bfs.dfs, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.preci.bfs.dfs)




p1.dif.preci.bfs.dfs = ics.aproach_exp01.precision %>% 
  filter(aproach != 'Epsilon-greedy') %>%  
  ggplot() + 
  geom_errorbar(aes(x =  reorder(aproach, -(median_value)), y = statistic, ymin = conf.low, ymax = conf.high), width = 0.05) +
  geom_point(aes(x=aproach, y=median_value), size=3) + 
  ylim(0.7, 1) +
  labs(x='Algoritmo', y="Precisão", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 

p2.dif.preci.bfs.dfs = ci.dif.preci.bfs.dfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 3) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray")) +
  geom_hline(yintercept = -0.5, color="#B2B0AF",)




grid.arrange(p1.dif.preci.bfs.dfs, p2.dif.preci.bfs.dfs, nrow = 1)
```

#### IC Diferença Precisão do Bfs e Epsilon-greedy

```{r}
# IC entre BFs e E-greedy

diff_mediana_precision.e_greedy.bfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  
  return(bfs-e_greedy)
}

booted.dif.preci.bfs.e_greedy <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_precision.e_greedy.bfs, 
               R = 4000)

ci.dif.preci.greedy.bfs = tidy(booted.dif.preci.bfs.e_greedy, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.preci.greedy.bfs)

p1.dif.preci.greedy.bfs = ics.aproach_exp01.precision %>% 
  filter(aproach != 'Dfs') %>%  
  ggplot() + 
  geom_errorbar(aes(x =  reorder(aproach, -(median_value)), y = statistic, ymin = conf.low, ymax = conf.high), width = 0.05) +
  geom_point(aes(x=aproach, y=median_value), size=3) + 
  ylim(0.7, 1) +
  labs(x='Algoritmo', y="Precisão", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.preci.greedy.bfs = ci.dif.preci.greedy.bfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 3) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = -0.5, color="#B2B0AF",)


grid.arrange(p1.dif.preci.greedy.bfs, p2.dif.preci.greedy.bfs, nrow = 1)

```


## F1 Score por cada Município da Amostra 


```{r}
metricas_result_exp01 %>% 
  group_by(municipio, aproach) %>% 
  summarise(max_value = max(f1_score), min_value = min(f1_score), median_value=median(f1_score)) %>% 
  ggplot(aes(y=municipio)) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=2,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=2, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='F1 Score', y=NULL, title="") +
  facet_grid(.~ aproach)  + 
  theme(legend.position = "top")

ggsave('exp01-f1score-by_municipios.png')

```


```{r eval=FALSE, include=FALSE}

#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

f1_score_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$f1_score)
    ))
}

create_ic.mun <- function(x, y) {
  x <- last(x)
  y <- last(y)
  
  df.boot.mun <- filter(metricas_result_exp01, aproach == x, municipio == y)
  
  bootstrap.aproach.mun <- boot(
          data = df.boot.mun, 
          statistic = f1_score_boot, 
          R = 4000 )
  
  print(glimpse(bootstrap.aproach.mun))

  
  ci = tidy(bootstrap.aproach.mun, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


boot.aproach_exp01.mun <- metricas_result_exp01 %>%
  group_by(aproach, municipio) %>% 
  summarise(
     median_value = median(f1_score),
     ci = create_ic.mun(aproach, municipio)
  ) %>% 
  unnest(ci)

  
boot.aproach_exp01.mun %>% 
  ggplot() + 
  geom_errorbar(aes(x = municipio, y = statistic, ymin = conf.low, ymax = conf.high), width = 0.05) +
  geom_point(aes(x=municipio, y=median_value), color='red', size=1) +
  coord_flip() +
  facet_grid(. ~aproach) 
  

```




## Tempo de Duração  

```{r}
metricas_result_exp01 %>%
  group_by(aproach)  %>%
  ggplot(aes(x = reorder(aproach, -(max_durationMin)), y = max_durationMin)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 17,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  labs(x='Algoritmo', y="Duração (Min)", title="", color = "") + 
  guides(fill=guide_legend(title="Algoritmo")) + 
  theme(legend.position = "top")

ggsave('exp01-duration.png')

```

## Nós Acessados  


```{r}
metricas_result_exp01 %>%
  group_by(aproach)  %>%
  ggplot(aes(x = reorder(aproach, -(max_num_access_node)), y = max_num_access_node)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 5,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "") + 
  guides(fill=guide_legend(title="Algoritmo")) + 
  theme(legend.position = "top")

ggsave('exp01-n-access-nodes.png')
```


## f1 Score por combinação

```{r}

metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(f1_score), min_value = min(f1_score), median_value=median(f1_score), dif = max_value - min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='F1 Score', y=NULL, title="") +
  facet_grid(.~ aproach)  + 
  theme(legend.position = "top")

ggsave('exp01-f1score-by_combinations.png')

```

## Número de nós acessados por combinação

```{r}

metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(max_num_access_node), min_value = min(max_num_access_node), median_value=median(max_num_access_node), dif = max_value-min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='Número de Nós Acessados', y=NULL, title="") +
  facet_grid(.~ aproach) + 
  theme(legend.position = "top")

ggsave('exp01-num_nodes_by_combinations.png')

```

## Duração das avaliações por combinações

```{r}
metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(max_durationMin), min_value = min(max_durationMin), median_value=median(max_durationMin), dif = max_value - min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='Duração (Min)', y=NULL, title="") +
  facet_grid(.~ aproach) + 
  theme(legend.position = "top")

ggsave('exp01-duration_nodes_by_combinations.png')

```

## Número de Avaliações por abordagem

```{r}
metricas_result_exp01 %>%
    group_by(municipio) %>%
    summarise(bfs = sum(aproach == 'Bfs'), dfs = sum(aproach == 'Dfs'), bandit = sum(aproach == 'Epsilon-greedy')) %>%
    arrange(desc(dfs)) %>%
    datatable(options = list(pageLength = 10),  rownames = FALSE, class = 'cell-border stripe')
```

## Todas as Avaliações

```{r}
metricas_result_exp01 %>%
    select(municipio, aproach, date, recall, precision, f1_score) %>%
    arrange(desc(recall)) %>% 
    datatable(options = list(pageLength = 10),  rownames = FALSE, class = 'cell-border stripe')
```

