---
title: "Experimento 01 Auditor Crawler"
output:
    html_document:
    css: styles.css
theme: sandstone
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse) # 
library(broom)
library(jsonlite) # Ler dados json
library(dplyr) # 
library(here)
library(DT)
library(boot)
library(ggalt)
set.seed(12345)
library(ggplot2)
library(ggbeeswarm)
source(here::here("code/lib.R"))
library(knitr)
library(kableExtra)
theme_set(theme_bw())
require(gridExtra)
```


## Problema 

A ausência de estratégias  de recuperação da informação eficientes e de caráter eficaz, com aplicação robusta no contexto da identificação e avaliação automática de critérios fiscais em portais de transparência municipais.

## Contexto

Com base no problema apresentado, este trabalho propôs a utilização e validação de crawlers para avaliar automaticamente portais municipais de transparência. Assim, durante a pesquisa foi implementado um crawler focado (crawlers aplicados a um contexto único) para avaliar os portais de transparência dos municipios do estado da Paraíba, utilizando como diretrizes de avaliação e validação da solução o Índice de transparência Municipal criado pelo Tribunal de Contas da Paraíba (TCE-PB). Por meio do ìndice foram elicitados todos os itens utilizados na avaliação de cada portal.

Neste contexto, com o objetivo de construir uma solução eficaz, eficiente e robusta foram experiementadas diferentes formas de buscar por novas páginas, partindo da premissa que o modo de percorrer e buscar novas páginas possui impacto direto na perfomace e manuteção destas caraterísticas. Desta forma, foram avaliados 3 diferentes algoritmos, sendo dois algoritmos tradicionais neste tipo de aplicação (BFS e DFS) e outro encontrado através da litertatura o E-greedy.    

## Experimento 1 

Neste experimento foi avaliado o desempenho do crawler focado na avaliação da transparênica comparando a uso dos Algoritmos Bfs, Dfs em relação ao Epsilon-greedy durante a busca e identificação dos critérios ficais nos sites de transparência. Este experimento tentar responder as seguintes perguntas:

1. Como se comporta o crawler em relação ao Recall e Precisão considerando os diferentes algoritmos durante as avaliações de transparência (Eficácia)?
2. Como se comporta o crawler em relação a número de nós acessados considerando os diferentes algoritmos durante as avaliações (Eficiência)?
3. Como é a estabilidade do crawler considerando cada um dos algoritmos e as combinação de portal de transparência?
4. Como se comporta a variação do crawler considerando os diferentes algoritmos e as combinações de transparência?


Para responder essas perguntas foram utilizadas as seguintes variáveis: 

* Recall de cada avaliação;
* Precisão de cada avaliação;
* Número máximo de nós acessados;
* Mediana do número de nós acessados;
* Duração máxima em minutos da avaliação;
* Mediana da duração da avaliação em minutos;
* Combinação de portais de transparência;

Obs: Um nó pode ser representado por um link ou um componente clicável em páginas da web.


```{r warning=FALSE, include=FALSE}
resultados_avaliacoes_exp01 = read_avaliacoes()
resultados_avaliacoes_exp01[is.na(resultados_avaliacoes_exp01)] <- ''
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "bandit", "Epsilon-greedy")
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "bfs", "Bfs")
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "dfs", "Dfs")


gararito = read_gabaritos()
gararito[is.na(gararito)] <- ''

empresas_portais <- readr::read_csv(here::here("data/empresas_portais.csv"))
```


## Avaliações válidas

As avaliações válidas são execuções do Crawler que tiveram entre os critérios fiscais avaliados 61 itens pesquisados. Deste modo, para evitar ruídos que possam impactar nos resultados, todas as avaliações que não contínham este padrão de validade foram descartadas. Além disso, as avaliações do município de ***Curral de Cima*** não foram consideradas por seu portal de transparência está atualmente fora do ar, restando 29 municípios na amostra.


```{r warning=FALSE, include=FALSE}
resultados_avaliacoes_exp01 <- resultados_avaliacoes_exp01 %>% 
  filter(tipo_exp == 'all_itens' & (municipio != 'Curral de Cima' & municipio != 'todo'))

```



```{r warning=FALSE, include=FALSE}
empresas_portais <- empresas_portais %>% 
    select(municipio, fornecedor)

gararito<-left_join(gararito, empresas_portais, by=c("municipio"))
```


```{r warning=FALSE, include=FALSE}
# concatena os dois csv o do gabarito e avaliações do crawler
data<-left_join(resultados_avaliacoes_exp01, gararito, by=c("municipio", "item", "criterio"))
```

## Um exemplo dos dados utilizados


```{r echo=FALSE}

sumarise_exp01 <- data %>% 
    group_by(id, municipio, criterio, item, aproach, date) %>% 
    mutate(
           
           #verifica se a avaliação foi acertiva
           tp = (valid == TRUE 
           & valid == encontrado 
           #valida se no gabarito e na avaliação o item foi encontrado na mesma url 
           & (grepl(local_encontrado, pathSought) |
                  grepl(local_encontrado_2, pathSought))) | (valid == FALSE 
           & valid == encontrado),
           
           fn =  valid == FALSE 
           & encontrado == TRUE,
           
           fp = valid == TRUE 
           & encontrado == FALSE
          )




kable(head(sumarise_exp01 %>%
  select(municipio, criterio, item, aproach, tp, contNodeNumberAccess, durationMin))) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) 
```



## Quantificando métricas

Calculando Recall, Precision, F1 Score e métricas relacionadas ao desempenho do Auditor Crawler.

```{r warning=FALSE, include=FALSE}

metricas_result_exp01 <- sumarise_exp01 %>% 
    #filter(!is.na(aproach )) %>% 
    group_by(municipio, aproach, date) %>% 
    summarise(
        total_itens = n(),
        tp_total = sum(tp), 
        fn_total = sum(fn),
        fp_total = sum(fp),
        
        #cálculo das métricas 
        recall = tp_total/(tp_total + fn_total),
        precision =  tp_total/(tp_total + fp_total),
        f1_score = (2*(recall*precision))/(recall+precision),
        
        #tempo das avaliações
        median_duration_min = median(durationMin),
        median_duration = median(duration),
        max_duration = max(duration),
        max_durationMin = max(durationMin),
        median_num_access_node = median(contNodeNumberAccess),
        mean_num_access_node = mean(contNodeNumberAccess),
        max_num_access_node = max(contNodeNumberAccess),
        all_access_node = sum(contNodeNumberAccess),
        combination = last(fornecedor),
        tipo_exp = last(tipo_exp)
    )


metricas_result_exp01 <- metricas_result_exp01 %>%
  filter(total_itens == 61  & recall > 0.46)

metricas_result_exp01 %>% 
    write_csv(here::here("data/resultados_sumarizado_exp01.csv"))

metricas_result_exp01 %>%
  arrange(desc(recall))

```


```{r warning=FALSE, include=FALSE}
metricas_result_exp01 <- metricas_result_exp01 %>%
  group_by(municipio, aproach) %>%
  mutate(variance_recall = sd(recall), recall_median = median(recall)) %>%
  ungroup() %>%
  mutate(recall_t = recall - recall_median ) %>%
  arrange(desc(recall_t), municipio, aproach) %>%
  group_by(municipio, aproach) %>%
  slice(seq_len(3)) %>%
  ungroup()
```

## Número de Avaliações por Algoritmo


```{r echo=FALSE}
metricas_result_exp01 %>%
    group_by(aproach) %>% 
    summarise(ocorrencia = n()) %>%
    ggplot(aes(y=ocorrencia, x=reorder(aproach, +(ocorrencia)))) + 
    geom_bar(stat = "identity",  fill="#5499C7") + 
    ggtitle("Número de Avaliações por Abordagem") +
    xlab("Abordagem") + 
    ylab("Número de avaliações") +
    coord_flip()
```

Foram coletadas entre os algoritmos 3 avaliações por portal de transparência. No total foram realizadas proporcionalmente 261 avalições dividas entre os 29 portais da amostra e os algoritmos de busca avaliados.

## Como se comporta o crawler em relação ao Recall e a Precisão considerando os diferentes algoritmos durante as avaliações de transparência (Eficácia)?

Para avaliar a eficácia do crawler com uso dos diferentes algoritmos propostos foram utilizadas as métricas Recall e Precisão. A escolha destas métricas foi motivada pela necessidade do equilíbrio entre os valores obtidos para Recall e Precision, em outras palavras, da necessidade de uma avaliação de transparência que consiga identificar a maior quantidade de itens possível (Recall) e que mantenha uma alta confiabilidade nos itens identificados (Precision). 

### Recall das avaliações por algoritmo

A Figura x apresenta a distribuição e a mediana dos valores de Recall das avaliações entre os diferentes algoritmos de buscas experimentados. 


```{r echo=FALSE}
metricas_result_exp01 %>%
  group_by(aproach) %>%
  mutate(median_value = median(recall)) %>%
  ungroup() %>%
  ggplot(aes(x =  reorder(aproach, -(median_value)), y = recall)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 0.00911,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  ylim(0.5, 1) +
  labs(x='Algoritmo', y="Recall", color = "") + 
  theme(legend.position = "top")

ggsave('exp01-distribuition-recall-fig01.png')

```

Na Figura x, é possível observar uma semelhança entre as distribuições do Recall nas avaliações para cada um dos algoritmos, estando a maior parte das avaliações entre as faixas de valores de 0.7 até 1. Apesar disto, existem alguns outiles situados abaixo destas faixas de valores e encontrados nos resultados obtidos com os algoritmos Epsilon-greedy e Dfs. Estes fazem parte de avaliações pertecentes ao portal de transparência do município de Remígio, ao qual o crawler utilizando Epsilon-greedy ou DFs não consegue lidar com as sessões temporárias dentro de iframes de forma efetiva, devido o acesso não sequencial aos nós e a má prática no uso de iframes embutidos nas páginas deste site. Além disso, comparando as medianas entre os algoritmos é imperceptível a diferença entre os métodos de busca, variando entre 0.90 (Epsilon-greedy) e 0.89 (Dfs e Bfs).


#### Intervalos de Confiança da mediana do Recall



```{r echo=FALSE}
#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

recall_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$recall)
    ))
}

create_ic.recall <- function(x) {
  x <- last(x)
  df.boot <- filter(metricas_result_exp01, aproach == x)
  
  bootstrap.aproach <- boot(
          data = df.boot, 
          statistic = recall_boot, 
          R = 4000 )
  
  ci = tidy(bootstrap.aproach, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


ics.aproach_exp01.recall <- metricas_result_exp01 %>%
  group_by(aproach) %>% 
   summarise(
     median_value = median(recall),
     ci = list(create_ic.recall(aproach))
  ) %>% 
  unnest(ci) 


```

#### IC Diferença Recall do Epsilon-greedy e Dfs

Como visto na Figura x, os algoritmos que obtiveram maiores valores Recall foram Epsilon-greedy e Dfs. Assim, foram criados intervalos de confiança para a diferença entre eles. Estes intervalos de confiança são mostrados na Figura u.

```{r echo=FALSE}
set.seed(123)

# IC entre DFs e E-greedy

diff_mediana_recall.e_greedy.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(e_greedy-dfs)
}

booted.dif <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_recall.e_greedy.dfs, 
               R = 4000)
ci.dif = tidy(booted.dif, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
glimpse(ci.dif)


p1.recall.e_greedy.dfs = ics.aproach_exp01.recall %>% 
  filter(aproach != 'Bfs') %>%  
  ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(0.8, 1) +
  labs(x='Algoritmo', y="Recall", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 


p2.recall.e_greedy.dfs = ci.dif %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 3) + 
  coord_flip(ylim = c(-0.2, 0.2)) +
  labs(x = "",
       y = "", title = 'Diferença Epsilon-greedy - Dfs') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)

grid.arrange(p1.recall.e_greedy.dfs, p2.recall.e_greedy.dfs, nrow = 1)

ggsave('exp01-ic-e-greedy-dfs.png')

```

A partir dos intervalos de confiança da mediana e da diferença entre os algoritmos Epsilon-greedy e Dfs mostrados na Figura u, é possível observar que os intervalos estão localizados entre 0.84 a 0.92 na Dfs e 0.88 a 0.92 no Epsilon-greedy. Além disso, baseado na diferença ***Epsilon-greedy-Dfs*** é possível verificar com 95% de confiança o sentido e a grandeza da diferença entre os algoritmos Epsilon greedy e Dfs em relação aos valores da mediana do Recall. As barras de erros do itervalo de confiança variam de -0.032 até 0.048, podendo assumir tanto valores positivos quanto negativos. Neste cenário, não é possível comprovar a existência de um desempenho superior no uso Epsilon-greedy na obtenção do Recall em comparação com a Dfs, devido ao pequeno intervalo e por ele conter o valor 0.


#### IC Diferença Recall do Epsilon-greedy e Bfs

De acordo com a Figura x, fica evidente a discreta variação (0.01) entre os resultados obtidos para Recall entre os agoritmos de busca. Sob esta pespectiva e considerando que o algoritmo Bfs é o algoritmo de busca base do crawler focado proposto neste trabalho, foram também comparados os algoritmos Epsilon-greedy e Bfs. Esta comparação foi realizada com crição a de intervalos de confiança para mediana dos dois algoritmos e a diferença entre as medianas deles.


```{r echo=FALSE}
# IC entre BFs e E-greedy

diff_mediana_recall.e_greedy.bfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  
  return(e_greedy-bfs)
}

booted.dif.recall.2 <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_recall.e_greedy.bfs, 
               R = 4000)

ci.dif.recall.greedy.bfs = tidy(booted.dif.recall.2, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.recall.greedy.bfs)

p1.recall.e_greedy.bfs = ics.aproach_exp01.recall %>% 
  filter(aproach != 'Dfs') %>%  
  ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(0.8, 1) +
  labs(x='Algoritmo', y="Recall", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  


p2.recall.e_greedy.bfs = ci.dif.recall.greedy.bfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 3) + 
  coord_flip(ylim = c(-0.2, 0.2)) +
  labs(x = "",
       y = "", title = 'Diferença Epsilon-greedy - Bfs') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.recall.e_greedy.bfs, p2.recall.e_greedy.bfs, nrow = 1)

ggsave('exp01-ic-e-greedy-bfs.png')

```

A partir dos intervalos de confiança da mediana e da diferença entre os algoritmos Epsilon-greedy e Bfs para os valores do Recall expostos na Figura p, é identificado que as medianas apresentadas nos intervalos concentram-se entre 0.87 até 0.91 na Dfs e 0.88 até 0.92 no Epsilon-greedy. Além disso, baseado na diferença ***Epsilon-greedy-Bfs*** é possível verificar com 95% de confiança o sentido e a grandeza da diferença entre os algoritmos Epsilon greedy e Dfs em relação aos valores da mediana do Recall. As barras de erros do itervalo de confiança variam de -0.036 até 0.030, podendo assumir tanto valores positivos quanto negativos. Neste contexto, a variação é mínima podedendo ser desconsiderada na distinção entre os valores da mediana do Recall no uso do Epsilon-greedy e Dfs.

De acordo com os resultados mostrados para os intervalos de confiança apresentados na Figura u e p, é possível extender os resultados para a comparação entre os algoritmos Dfs e Bfs, devido a semelhança entre os resultados obtidos. Além disso, de acordo com os intervalos não foi possível confirmar a existência de uma superioridade nos valores para a mediana do Recall durante as avaliações no uso destes algoritmos. 

### Precisão das avaliações por algoritmo

A Figura y exibe a distribuição e a mediana dos valores da Precisão das avaliações entre os diferentes algoritmos de buscas experimentados. 

```{r echo=FALSE}
metricas_result_exp01 %>%
  group_by(aproach) %>%
  mutate(median_value = median(precision)) %>%
  ungroup() %>%
  ggplot(aes(x = reorder(aproach, -(median_value)), y = precision)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 0.00915,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  labs(x='Algoritmo', y="Precisão", title="", color = "") + 
  guides(fill=guide_legend(title="Algoritmo")) + 
  ylim(0.5, 1) +
  theme(legend.position = "top")

ggsave('exp01-distribuition-precision.png')
```

Com base na Figura y, constata-se que as faixas de valores da Precisão das avaliações entre os algoritmos são similares, variando entre 0.85 até 1. Ademais, os valores das medianas apresentaram pequenas mudanças nos mesmos, situados entre 0.95 (Epsilon-greedy e Dfs) e 0.96 (Bfs). Porém, esta variação, assim como nas medianas do Recall, é de apenas 0.01. Assim, para avaliar as diferenças nestes valores foram criados itervalos de confiança para a mediana dos algoritmos de busca. 

#### Intervalos de Confiança da mediana de Precisão

```{r echo=FALSE}
#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

precision_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$precision)
    ))
}

create_ic.precision <- function(x) {
  x <- last(x)
  df.boot <- filter(metricas_result_exp01, aproach == x)
  
  bootstrap.aproach.precision <- boot(
          data = df.boot, 
          statistic = precision_boot, 
          R = 4000 )
  
  ci = tidy(bootstrap.aproach.precision, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


ics.aproach_exp01.precision <- metricas_result_exp01 %>%
  group_by(aproach) %>% 
   summarise(
     median_value = median(precision),
     ci = list(create_ic.precision(aproach))
  ) %>% 
  unnest(ci) 

```

#### IC Diferença Precisão do Bfs e Dfs


```{r echo=FALSE}
set.seed(123)

# IC entre DFs e BFS

diff_mediana_precision.bfs.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(bfs-dfs)
}

booted.dif.preci.bfs.dfs <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_precision.bfs.dfs, 
               R = 4000)

ci.dif.preci.bfs.dfs = tidy(booted.dif.preci.bfs.dfs, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.preci.bfs.dfs)




p1.dif.preci.bfs.dfs = ics.aproach_exp01.precision %>% 
  filter(aproach != 'Epsilon-greedy') %>%  
  ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(aes(x=aproach, y=median_value), size=2) + 
  ylim(0.8, 1) +
  labs(x='Algoritmo', y="Precisão", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 

p2.dif.preci.bfs.dfs = ci.dif.preci.bfs.dfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "", title = 'Diferença Bfs - Dfs') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)

grid.arrange(p1.dif.preci.bfs.dfs, p2.dif.preci.bfs.dfs, nrow = 1)

ggsave('exp01-ic-prec-e-bfs-dfs.png')

```

Por meio dos intervalos de confiança da mediana e da diferença para a Precisão dos algoritmos Bfs e Dfs apresentados na Figura t, é notado que os intervalos das medianas da Precisão estão em 0.94 a 0.95 na Dfs e 0.94 a 0.96 para a Bfs. Ademais, embasado na diferença ***Bfs - Dfs***  não é possível constatar pelo intervalo -0.036 a 0.042 a existência de uma diferença entre os algoritmos em relação aos valores da mediana da Precisão, devido ao intervalo ser pequeno e conter o valor 0.

#### IC Diferença Precisão do Bfs e Epsilon-greedy

```{r echo=FALSE}
# IC entre BFs e E-greedy

diff_mediana_precision.e_greedy.bfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  
  return(bfs-e_greedy)
}

booted.dif.preci.bfs.e_greedy <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_precision.e_greedy.bfs, 
               R = 4000)

ci.dif.preci.greedy.bfs = tidy(booted.dif.preci.bfs.e_greedy, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.preci.greedy.bfs)

p1.dif.preci.greedy.bfs = ics.aproach_exp01.precision %>% 
  filter(aproach != 'Dfs') %>%  
 ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(aes(x=aproach, y=median_value), size=2) + 
  ylim(0.8, 1) +
  labs(x='Algoritmo', y="Precisão", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.preci.greedy.bfs = ci.dif.preci.greedy.bfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-0.2, 0.2)) +
  labs(x = "",
       y = "", title = 'Diferença Bfs - Epsilon-greedy') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.dif.preci.greedy.bfs, p2.dif.preci.greedy.bfs, nrow = 1)
ggsave('exp01-ic-prec-e-e-greedy-bfs.png')

```

De acordo com a Figura v é notado que os intervalos das medianas da Precisão estão em 0.93 a 0.94 no Epsilon-greedy e 0.94 a 0.96 para a Bfs. Além disso, por meio do intervalo da diferença entre ***Bfs - Epsilon-greedy*** é observado que o mesmo contém 0 em sua faixa de valores e apresenta pequenos valore ficando entre -0.03 até 0.03. Assim, com aplicação dos intervalos com 95% de confiança, não foi possível indentificar uma clara diferença entre os valores obtidos para a mediana no uso dos algoritmos Bfs e Epsilon-greedy.


#### Conclusões

A partir dos resultados encontrados é percebido que não existe uma diferenciação clara nas medianas dos algoritmos em relação aos valores de Recall e Precisão. Assim, é possível que não exista diferença no uso do crawler com os algoritmos de busca experiementados em relação as estas métricas.

Neste contexto, a discreta alteração nos resultados entre os algoritmos pode refletir a ocorrência de instabilidades no link de internet utilizado, no site de transparência ou no processamento das avaliações durante as execuções entre os distintos algoritmos, dado que todas as avaliações foram realizadas em tempo real e online, com o acesso as URLs oficiais dos portais de transparência. Além disso, a igualdade entre as métricas pode retratar a conversação na forma de identificar novos nós, baseando-se em palavras chaves relacionadas ao critério fiscal buscado. Desta forma, o crawler não alterou seu comportamento em relação a quais nós eram descobertos mas na maneira de pecorrer e selecionar cada um deles.

## Como se comporta o crawler em relação a número de nós acessados considerando os diferentes algoritmos durante as avaliações (Eficiência)?

Para avaliar a perfomance do Crawler focado com o uso dos diferentes algoritmos, foi empregado o uso a mediana do número de nós acessados entre os critérios fiscais pesquisados em cada avaliação. Esta métrica foi escolhida em virtude de sua maior estabilidade em relação a possíveis instabilidades ocorridas durante as avaliações, pois independentemente da duração da avaliação, o número de nós acessados deve permancer similar considerando um mesmo portal. Neste cenário, a Figura y mostra a distribuição da mediana do número de nós acessados entre os critérios fiscais nas avaliações entre os três algoritmos testados.

```{r echo=FALSE}
metricas_result_exp01 %>%
  ggplot(aes(x = reorder(aproach, +(median_num_access_node)), y = median_num_access_node)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 2,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "") + 
  guides(fill=guide_legend(title="Algoritmo")) + 
  theme(legend.position = "top")

ggsave('exp01-n-access-nodes.png')
```

Conforme é exposto na Figura y, a maioria das avaliações possuem nós entre as faixas de valores de 4 a 60 nós. No entanto, existem algumas exeções com avaliações de Itabaiana para os algoritmos de Epsilon-greedy e Dfs, com os valores das medianas de nós acessados entre as faixas de 76 a 90. Além disso, sob este contexto, é detectado também algumas medianas de nós acessados pertecentes a avaliações de Bayeux nos algoritmos Dfs e Bfs que destoam da franção principal das avaliação, com mediana de nós acessados em respectivamente 68 e 108. Isto pode ter ocorrido devido a oscilações na internet ou no próprio site de transparência que possam ter afetado tais avaliações. Esta afirmação embase-se na não recorrência deste efeito dentre as demais avaliações para o mesmo município. Ademais, é possível constatar em relação ao valor da mediana da distribuição que o algoritmo Bfs apresentou o melhor resultado com menos nós acessados seguindo pelo algoritmo com a mediana de 14 nós acessados Epsilon-greedy (16) e Dfs (18).

Para validar essa análise, aplicamos intervalos de confiança com a utilização de bootstraps (4000).

### Intervalos de confiança para Número de Nós acessados 

Com base no objetivo de avaliar o algoritmo Epsilon-greedy em relação a algoritmos clássicos no que se refere a busca por novas páginas no processo de crawling, foram criados intervalos de confiança para a mediana de nós acessados entre os critérios fiscais para os algoritmos Bfs que obteve melhor resultado e o Epsilon-greedy.  


```{r echo=FALSE}
#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

median_num_access_node_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$median_num_access_node)
    ))
}

create_ic_median_num_access_node <- function(x) {
  x <- last(x)
  df.boot <- filter(metricas_result_exp01, aproach == x)
  
  bootstrap.aproach.median_num_access_node <- boot(
          data = df.boot, 
          statistic = median_num_access_node_boot, 
          R = 4000 )
  
  ci = tidy(bootstrap.aproach.median_num_access_node, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


ics.aproach_exp01.median_num_access_node <- metricas_result_exp01 %>%
  group_by(aproach) %>% 
   summarise(
     median_value = median(median_num_access_node),
     ci = list(create_ic_median_num_access_node(aproach))
  ) %>% 
  unnest(ci) 

```

#### IC Diferença Mediana do Número de nós do Bfs e Epsilon-greedy


```{r echo=FALSE}

diff_median_num_access.e_greedy.bfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(median_num_access_node))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  
  return(bfs-e_greedy)
}

booted.dif.median_num_access.bfs.e_greedy <- boot(data = metricas_result_exp01, 
               statistic = diff_median_num_access.e_greedy.bfs, 
               R = 4000)

ci.dif.median_num_access.bfs.e_greedy.greedy = tidy(booted.dif.median_num_access.bfs.e_greedy, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.median_num_access.bfs.e_greedy.greedy)

p1.dif.median_num_access.bfs.e_greedy= ics.aproach_exp01.median_num_access_node %>% 
  filter(aproach != 'Dfs') %>%  
 ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(8, 30) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.median_num_access.greedy.bfs = ci.dif.median_num_access.bfs.e_greedy.greedy %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-8, 8)) +
  labs(x = "",
       y = "", title = 'Diferença Bfs - Epsilon-greedy') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.dif.median_num_access.bfs.e_greedy, p2.dif.median_num_access.greedy.bfs, nrow = 1)

```



#### IC Diferença Mediana do Número de nós do dfs e Epsilon-greedy


```{r echo=FALSE}

diff_median_num_access.e_greedy.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(median_num_access_node))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(e_greedy-dfs)
}

booted.dif.median_num_access.dfs.e_greedy <- boot(data = metricas_result_exp01, 
               statistic = diff_median_num_access.e_greedy.dfs, 
               R = 4000)

ci.dif.median_num_access.dfs.e_greedy.greedy = tidy(booted.dif.median_num_access.dfs.e_greedy, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.median_num_access.dfs.e_greedy.greedy)

p1.dif.median_num_access.dfs.e_greedy= ics.aproach_exp01.median_num_access_node %>% 
  filter(aproach != 'Bfs') %>%  
 ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(8, 30) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.median_num_access.greedy.dfs = ci.dif.median_num_access.dfs.e_greedy.greedy %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-8, 8)) +
  labs(x = "",
       y = "", title = 'Diferença Epsilon-greedy - Dfs') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.dif.median_num_access.dfs.e_greedy, p2.dif.median_num_access.greedy.dfs, nrow = 1)

```

#### IC Diferença Mediana do Número de nós do dfs e Epsilon-greedy


```{r echo=FALSE}

diff_median_num_access.bfs.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(median_num_access_node))
  
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(bfs-dfs)
}

booted.dif.median_num_access.dfs.bfs <- boot(data = metricas_result_exp01, 
               statistic = diff_median_num_access.bfs.dfs, 
               R = 4000)

ci.dif.median_num_access.dfs.bfs = tidy(booted.dif.median_num_access.dfs.bfs, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.median_num_access.dfs.bfs)

p1.dif.median_num_access.dfs.bfs = ics.aproach_exp01.median_num_access_node %>% 
  filter(aproach != 'Epsilon-greedy') %>%  
 ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(8, 30) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.median_num_access.bfs.dfs = ci.dif.median_num_access.dfs.bfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-8, 8)) +
  labs(x = "",
       y = "", title = 'Diferença Bfs - Dfs') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.dif.median_num_access.dfs.bfs, p2.dif.median_num_access.bfs.dfs, nrow = 1)

```

## F1 Score por cada Município da Amostra 


```{r echo=FALSE}
metricas_result_exp01 %>% 
  group_by(municipio, aproach) %>% 
  summarise(max_value = max(f1_score), min_value = min(f1_score), median_value=median(f1_score)) %>% 
  ggplot(aes(y=municipio)) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=2,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=2, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='F1 Score', y=NULL, title="") +
  facet_grid(.~ aproach)  + 
  theme(legend.position = "top")

ggsave('exp01-f1score-by_municipios.png')

```

## f1 Score por combinação

```{r echo=FALSE}

metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(f1_score), min_value = min(f1_score), median_value=median(f1_score), dif = max_value - min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='F1 Score', y=NULL, title="") +
  facet_grid(.~ aproach)  + 
  theme(legend.position = "top")

ggsave('exp01-f1score-by_combinations.png')

```

## Número de nós acessados por combinação

```{r echo=FALSE}

metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(max_num_access_node), min_value = min(max_num_access_node), median_value=median(max_num_access_node), dif = max_value-min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='Número de Nós Acessados', y=NULL, title="") +
  facet_grid(.~ aproach) + 
  theme(legend.position = "top")

ggsave('exp01-num_nodes_by_combinations.png')

```

## Duração das avaliações por combinações

```{r echo=FALSE}
metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(max_durationMin), min_value = min(max_durationMin), median_value=median(max_durationMin), dif = max_value - min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='Duração (Min)', y=NULL, title="") +
  facet_grid(.~ aproach) + 
  theme(legend.position = "top")

ggsave('exp01-duration_nodes_by_combinations.png')

```

## Número de Avaliações por abordagem

```{r echo=FALSE}
metricas_result_exp01 %>%
    group_by(municipio) %>%
    summarise(bfs = sum(aproach == 'Bfs'), dfs = sum(aproach == 'Dfs'), bandit = sum(aproach == 'Epsilon-greedy')) %>%
    arrange(desc(dfs)) %>%
    datatable(options = list(pageLength = 10),  rownames = FALSE, class = 'cell-border stripe')
```

## Todas as Avaliações

```{r echo=FALSE}
metricas_result_exp01 %>%
    select(municipio, aproach, date, recall, precision, f1_score) %>%
    arrange(desc(recall)) %>% 
    datatable(options = list(pageLength = 10),  rownames = FALSE, class = 'cell-border stripe')
```

