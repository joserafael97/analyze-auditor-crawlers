---
title: "Experimento 01 Auditor Crawler"
output:
    html_document:
    css: styles.css
theme: sandstone
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse) # 
library(broom)
library(jsonlite) # Ler dados json
library(dplyr) # 
library(here)
library(DT)
library(boot)
library(ggalt)
set.seed(12345)
library(ggplot2)
library(ggbeeswarm)
source(here::here("code/lib.R"))
library(knitr)
library(kableExtra)
theme_set(theme_bw())
require(gridExtra)
```


## Problema 

A ausência de estratégias  de recuperação da informação eficientes e de caráter eficaz, com aplicação robusta no contexto da identificação e avaliação automática de critérios fiscais em portais de transparência municipais.

## Contexto

Com base no problema apresentado, este trabalho propôs a utilização e validação de crawlers para avaliar automaticamente portais municipais de transparência. Assim, durante a pesquisa foi implementado um crawler focado (crawlers aplicados a um contexto único) para avaliar os portais de transparência dos municipios do estado da Paraíba, utilizando como diretrizes de avaliação e validação da solução o Índice de transparência Municipal criado pelo Tribunal de Contas da Paraíba (TCE-PB). Por meio do ìndice foram elicitados itens para serem classificados como presentes ou ausentes em cada portal.

Neste contexto, com o objetivo de construir uma solução eficaz, eficiente e robusta foram experiementadas diferentes formas de buscar por novas páginas, partindo da premissa que o modo de percorrer e buscar novas páginas é tem impacto direto na manuteção destas métricas. Desta forma, foram avaliados 3 diferentes algoritmos neste aspaceto, sendo dois algoritmos tradicionais neste tipo de aplicação BFS e DFS e outro encontrado na litertatura o E-greedy.    

## Experimento 1 

Neste experimento foi avaliado o desempenho do crawler focado na avaliação da transparênica e a utilização dos Algoritmos BFS, DFS em relação ao Epsilon-greedy durante a busca e identificação dos critérios ficais nos sites de transparência. Este experimento tentar responder as seguintes perguntas:

1. Como se comporta o crawler em relação ao Recall e Precisão considerando os diferentes algoritmos durante as avaliações de transparência (Eficácia)?
2. Como se comporta o crawler em relação a número de nós acessados considerando os diferentes algoritmos durante as avaliações (Eficiência)?
3. Como é a estabilidade do crawler considerando cada um dos algoritmos e as combinação de portal de transparência?
4. Como se comporta a variação do crawler considerando os diferentes algoritmos e as combinações de transparência?


Para responder essas perguntas foram utilizadas as seguintes variáveis: 

* Recall de cada avaliação;
* Precisão de cada avaliação;
* Número máximo de nós acessados;
* Mediana do número de nós acessados;
* Duração máxima em minutos da avaliação;
* Mediana da duração da avaliação em minutos;
* Combinação de portais de transparência;

Obs: Um nó pode ser representado por um link ou componente clicável em páginas da web.


```{r warning=FALSE, include=FALSE}
resultados_avaliacoes_exp01 = read_avaliacoes()
resultados_avaliacoes_exp01[is.na(resultados_avaliacoes_exp01)] <- ''
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "bandit", "Epsilon-greedy")
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "bfs", "Bfs")
resultados_avaliacoes_exp01$aproach <- replace(as.character(resultados_avaliacoes_exp01$aproach), resultados_avaliacoes_exp01$aproach == "dfs", "Dfs")


gararito = read_gabaritos()
gararito[is.na(gararito)] <- ''

empresas_portais <- readr::read_csv(here::here("data/empresas_portais.csv"))
```


## Avaliações válidas

As avaliações válidas são excuções do Crawler que tiveram entre os critérios fiscais avaliados 61 itens pesquisados. Deste modo, para evitar ruídos que possam impactar nos resultados obtidos, todas as avaliações que não contínham este padrão de validade foram descartadas. Além disso, as avaliações do município de ***Curral de Cima*** não foram consideradas por seu portal de transparência está atualmente fora do ar, restando 29 municípios na amostra.


```{r warning=FALSE, include=FALSE}
resultados_avaliacoes_exp01 <- resultados_avaliacoes_exp01 %>% 
  filter(tipo_exp == 'all_itens' & (municipio != 'Curral de Cima' & municipio != 'todo'))

```



```{r warning=FALSE, include=FALSE}
empresas_portais <- empresas_portais %>% 
    select(municipio, fornecedor)

gararito<-left_join(gararito, empresas_portais, by=c("municipio"))
```


```{r warning=FALSE, include=FALSE}
# concatena os dois csv o do gabarito e avaliações do crawler
data<-left_join(resultados_avaliacoes_exp01, gararito, by=c("municipio", "item", "criterio"))
```

## Um exemplo dos dados utilizados


```{r echo=FALSE}

sumarise_exp01 <- data %>% 
    group_by(id, municipio, criterio, item, aproach, date) %>% 
    mutate(
           
           #verifica se a avaliação foi acertiva
           tp = (valid == TRUE 
           & valid == encontrado 
           #valida se no gabarito e na avaliação o item foi encontrado na mesma url 
           & (grepl(local_encontrado, pathSought) |
                  grepl(local_encontrado_2, pathSought))) | (valid == FALSE 
           & valid == encontrado),
           
           fn =  valid == FALSE 
           & encontrado == TRUE,
           
           fp = valid == TRUE 
           & encontrado == FALSE
          )




kable(head(sumarise_exp01 %>%
  select(municipio, criterio, item, aproach, tp, contNodeNumberAccess, durationMin))) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) 
```



## Quantificando métricas

Calculando Recall, Precision, F1 Score e métricas relacionadas ao desempenho do Auditor Crawler.

```{r warning=FALSE, include=FALSE}

metricas_result_exp01 <- sumarise_exp01 %>% 
    #filter(!is.na(aproach )) %>% 
    group_by(municipio, aproach, date) %>% 
    summarise(
        total_itens = n(),
        tp_total = sum(tp), 
        fn_total = sum(fn),
        fp_total = sum(fp),
        
        #cálculo das métricas 
        recall = tp_total/(tp_total + fn_total),
        precision =  tp_total/(tp_total + fp_total),
        f1_score = (2*(recall*precision))/(recall+precision),
        
        #tempo das avaliações
        median_duration_min = median(durationMin),
        median_duration = median(duration),
        max_duration = max(duration),
        max_durationMin = max(durationMin),
        median_num_access_node = median(contNodeNumberAccess),
        max_num_access_node = max(contNodeNumberAccess),
        all_access_node = sum(contNodeNumberAccess),
        combination = last(fornecedor),
        tipo_exp = last(tipo_exp)
    )


metricas_result_exp01 <- metricas_result_exp01 %>%
  filter(total_itens == 61  & recall > 0.46)

metricas_result_exp01 %>% 
    write_csv(here::here("data/resultados_sumarizado_exp01.csv"))

metricas_result_exp01 %>%
  arrange(desc(recall))

```


```{r warning=FALSE, include=FALSE}
metricas_result_exp01 <- metricas_result_exp01 %>%
  group_by(municipio, aproach) %>%
  mutate(variance_recall = sd(recall), recall_median = median(recall)) %>%
  ungroup() %>%
  mutate(recall_t = recall - recall_median ) %>%
  arrange(desc(recall_t), municipio, aproach) %>%
  group_by(municipio, aproach) %>%
  slice(seq_len(3)) %>%
  ungroup()
```

## Número de Avaliações por Algoritmo


```{r echo=FALSE}
metricas_result_exp01 %>%
    group_by(aproach) %>% 
    summarise(ocorrencia = n()) %>%
    ggplot(aes(y=ocorrencia, x=reorder(aproach, +(ocorrencia)))) + 
    geom_bar(stat = "identity",  fill="#5499C7") + 
    ggtitle("Número de Avaliações por Abordagem") +
    xlab("Abordagem") + 
    ylab("Número de avaliações") +
    coord_flip()
```

Foram coletadas entre os algoritmos 3 avaliações por portal de transparência. No total foram realizadas proporcionalmente 261 avalições dividas entre os 29 portais da amostra e os algoritmos de busca avaliados.

## Como se comporta o crawler em relação ao Recall e a Precisão considerando os diferentes algoritmos durante as avaliações de transparência (Eficácia)?

Para avaliar a eficácia do crawler com uso dos diferentes algoritmos propostos foram utilizadas a métricas de Recall e Precisão. A escolha destas métricas foi motivada pela necessidade do equilíbrio entre os valores obtidos para Recall e Precision, em outras palavras, da necessidade de uma avaliação de transparência que consiga identificar a maior quantidade de itens possível (Recall) e que mantenha uma alta confiabilidade nos itens identificados (Precision). 

### Recall das avaliações por algoritmo

A Figura x apresenta a distribuição e a mediana dos valores de Recall das avaliações entre os diferentes algoritmos de buscas experimentados. 


```{r echo=FALSE}
metricas_result_exp01 %>%
  group_by(aproach) %>%
  mutate(median_value = median(recall)) %>%
  ungroup() %>%
  ggplot(aes(x =  reorder(aproach, -(median_value)), y = recall)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 0.00915,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  ylim(0.5, 1) +
  labs(x='Algoritmo', y="Recall", color = "") + 
  theme(legend.position = "top")

ggsave('01-exp01-distribuition-recall.png')

```

Na Figura x, é possível observar uma semelhança entre as distribuições do Recall nas avaliações para cada um dos algoritmos, estando a maior parte das avaliações entre as faixas de valores de 0.7 até 1. Apesar disto, existem alguns outiles situados abaixo destas faixas de valores e encontrados nos resultados obtidos com os algoritmos Epsilon-greedy e Dfs. Estes fazem parte de avaliações pertecentes ao portal de transparência do município de Remígio, ao qual o crawler utilizando Epsilon-greedy ou DFs não consegue lidar com as sessões temporárias dentro de iframes de forma efetiva, devido o acesso não sequencial aos nós e a má prática no uso de iframes embutidos nas páginas deste site. Além disso, comparando as medianas entre os algoritmos é imperceptível a diferença entre os métodos de busca, variando entre 0.90 (Epsilon-greedy) e 0.89 (Dfs e Bfs).


#### Intervalos de Confiança da mediana do Recall



```{r echo=FALSE}
#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

recall_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$recall)
    ))
}

create_ic.recall <- function(x) {
  x <- last(x)
  df.boot <- filter(metricas_result_exp01, aproach == x)
  
  bootstrap.aproach <- boot(
          data = df.boot, 
          statistic = recall_boot, 
          R = 4000 )
  
  ci = tidy(bootstrap.aproach, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


ics.aproach_exp01.recall <- metricas_result_exp01 %>%
  group_by(aproach) %>% 
   summarise(
     median_value = median(recall),
     ci = list(create_ic.recall(aproach))
  ) %>% 
  unnest(ci) 


```

#### IC Diferença Recall do Epsilon-greedy e Dfs

Como visto na Figura x, os algoritmos que obtiveram maiores valores Recall foram Epsilon-greedy e Dfs. Assim, foram criados intervalos de confiança para a diferença entre eles. Estes intervalos de confiança são mostrados na Figura u 

```{r echo=FALSE}
set.seed(123)

# IC entre DFs e E-greedy

diff_mediana_recall.e_greedy.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(e_greedy-dfs)
}

booted.dif <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_recall.e_greedy.dfs, 
               R = 4000)
ci.dif = tidy(booted.dif, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
glimpse(ci.dif)


p1.recall.e_greedy.dfs = ics.aproach_exp01.recall %>% 
  filter(aproach != 'Bfs') %>%  
  ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(0.7, 1) +
  labs(x='Algoritmo', y="Recall", title="IC da Mediana do valor do Recall", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 


p2.recall.e_greedy.dfs = ci.dif %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 3) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "", title = 'IC da Diferença Epsilon-greedy - Dfs') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)

grid.arrange(p1.recall.e_greedy.dfs, p2.recall.e_greedy.dfs, nrow = 1)

```

A partir dos intervalos de confiança da mediana e da diferença entre os algoritmos Epsilon-greedy e Dfs mostrados na Figura u, é possível observar que os intervalos para mediana do Recall contêm os valores da mediana dos dois algoritmo apresentados na amostra, estando entre 0.84 a 0.92 na Dfs e 0.88 a 0.92 no Epsilon-greedy. Sob esta pespectiva, é possível constatar uma discreta tendência das medianas a direita no Epsilon-greedy e a esquerda na Dfs. Além disso, baseado na diferença ***Epsilon-greedy-Dfs*** é possível verificar com 95% de confiança o sentido e a grandeza da diferença entre os algoritmos Epsilon greedy e Dfs em relação aos valores da mediana do Recall. As barras de erros do itervalo de confiança variam de -0.032 até 0.048, podendo assumir tanto valores positivos quanto negativos. Neste cenário, não é possível comprovar a existência de um desempenho superior no uso Epsilon-greedy na obtenção do Recall em comparação com a Dfs.


#### IC Diferença Recall do Epsilon-greedy e Bfs

De acordo com a Figura x, fica evidente a discreta variação (0.01) entre os resultados obtidos para Recall entre os agoritmos de busca. Sob esta pespectiva e considerando que o algoritmo Bfs é o algoritmo de busca base do crawler focado proposto neste trabalho, foram também comparados os algoritmos Epsilon-greedy e Bfs. Esta comparação foi realizada com crição de intervalos de confiança para mediana dos dois algoritmos e a diferença entre as medianas deles.


```{r echo=FALSE}
# IC entre BFs e E-greedy

diff_mediana_recall.e_greedy.bfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  
  return(e_greedy-bfs)
}

booted.dif.recall.2 <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_recall.e_greedy.bfs, 
               R = 4000)

ci.dif.recall.greedy.bfs = tidy(booted.dif.recall.2, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.recall.greedy.bfs)

p1.recall.e_greedy.bfs = ics.aproach_exp01.recall %>% 
  filter(aproach != 'Dfs') %>%  
  ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(0.7, 1) +
  labs(x='Algoritmo', y="Recall", title="IC da Mediana do valor do Recall", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  


p2.recall.e_greedy.bfs = ci.dif.recall.greedy.bfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 3) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "", title = 'IC da Diferença Epsilon-greedy - Bfs') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.recall.e_greedy.bfs, p2.recall.e_greedy.bfs, nrow = 1)

```

A partir dos intervalos de confiança da mediana e da diferença entre os algoritmos Epsilon-greedy e Bfs expostos na Figura p, é possível observar que os intervalos para mediana do Recall contêm os valores da mediana em ambos os algoritmos, estando entre 0.87 a 0.91 na Dfs e 0.88 a 0.92 no Epsilon-greedy. Sob esta pespectiva, é possível constatar uma discreta tendência das medianas a direita no Epsilon-greedy e a esquerda na Dfs. Além disso, baseado na diferença ***Epsilon-greedy-Bfs*** é possível verificar com 95% de confiança o sentido e a grandeza da diferença entre os algoritmos Epsilon greedy e Dfs em relação aos valores da mediana do Recall. As barras de erros do itervalo de confiança variam de -0.036 até 0.030, podendo assumir tanto valores positivos quanto negativos. Neste contexto, a variação é mínima podedendo ser desconsiderada na relação da diferença entre os valores da mediana do Recall no uso do Epsilon-greedy e Dfs. 

De acordo com os intervalos de confiança apresentados na Figura u e p, ao criar intervalos de confiança entre Epsilon greedy e Dfs e Epsilon greedy e Bfs é plausível extender os resultados para a comparação entre os algoritmos Dfs e Bfs, devido a semelhança entre os resultados obtidos. Além disso, de acordo com os intervalos não foi possível confirmar nenhuma superioridade nos valores para a mediana do Recall durante as avaliações no uso destes algoritmos. 

### Precisão das avaliações por algoritmo

A Figura y exibe a distribuição e a mediana dos valores da Precisão das avaliações entre os diferentes algoritmos de buscas experimentados. 


```{r echo=FALSE}
metricas_result_exp01 %>%
  group_by(aproach) %>%
  mutate(median_value = median(precision)) %>%
  ungroup() %>%
  ggplot(aes(x = reorder(aproach, -(median_value)), y = precision)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 0.00915,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  labs(x='Algoritmo', y="Precisão", title="", color = "") + 
  guides(fill=guide_legend(title="Algoritmo")) + 
  ylim(0.5, 1) +
  theme(legend.position = "top")

ggsave('exp01-distribuition-precision.png')
```

Com base na Figura y, constata-se que as faixas de valores da Precisão das avaliações entre os algoritmos são similares, variando entre 0.85 até 1. Ademais, os valores das medianas apresentaram pequenas mudanças nos mesmos, situados entre 0.95 (Epsilon-greedy e Dfs) e 0.96 (Bfs). Porém, esta variação, assim como nas medianas do Recall, é de apenas 0.01. Assim, para verificar avaliar as diferenças nestes valores foram criados itervalos de confiança para a mediana dos algoritmos de busca. 

#### Intervalos de Confiança da mediana de Precisão

```{r echo=FALSE}
#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

precision_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$precision)
    ))
}

create_ic.precision <- function(x) {
  x <- last(x)
  df.boot <- filter(metricas_result_exp01, aproach == x)
  
  bootstrap.aproach.precision <- boot(
          data = df.boot, 
          statistic = precision_boot, 
          R = 4000 )
  
  ci = tidy(bootstrap.aproach.precision, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


ics.aproach_exp01.precision <- metricas_result_exp01 %>%
  group_by(aproach) %>% 
   summarise(
     median_value = median(precision),
     ci = list(create_ic.precision(aproach))
  ) %>% 
  unnest(ci) 

```

#### IC Diferença Precisão do Bfs e Dfs



```{r echo=FALSE}
set.seed(123)

# IC entre DFs e BFS

diff_mediana_precision.bfs.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(bfs-dfs)
}

booted.dif.preci.bfs.dfs <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_precision.bfs.dfs, 
               R = 4000)

ci.dif.preci.bfs.dfs = tidy(booted.dif.preci.bfs.dfs, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.preci.bfs.dfs)




p1.dif.preci.bfs.dfs = ics.aproach_exp01.precision %>% 
  filter(aproach != 'Epsilon-greedy') %>%  
  ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(aes(x=aproach, y=median_value), size=2) + 
  ylim(0.7, 1) +
  labs(x='Algoritmo', y="Precisão", title="IC da Mediana do valor da Precisão", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 

p2.dif.preci.bfs.dfs = ci.dif.preci.bfs.dfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "", title = 'IC da Diferença Bfs - Dfs') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)




grid.arrange(p1.dif.preci.bfs.dfs, p2.dif.preci.bfs.dfs, nrow = 1)
```




#### IC Diferença Precisão do Bfs e Epsilon-greedy

```{r echo=FALSE}
# IC entre BFs e E-greedy

diff_mediana_precision.e_greedy.bfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(recall))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  
  return(bfs-e_greedy)
}

booted.dif.preci.bfs.e_greedy <- boot(data = metricas_result_exp01, 
               statistic = diff_mediana_precision.e_greedy.bfs, 
               R = 4000)

ci.dif.preci.greedy.bfs = tidy(booted.dif.preci.bfs.e_greedy, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.preci.greedy.bfs)

p1.dif.preci.greedy.bfs = ics.aproach_exp01.precision %>% 
  filter(aproach != 'Dfs') %>%  
 ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(aes(x=aproach, y=median_value), size=2) + 
  ylim(0.7, 1) +
  labs(x='Algoritmo', y="Precisão", title="IC da Mediana do valor da Precisão", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.preci.greedy.bfs = ci.dif.preci.greedy.bfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-0.5, 0.5)) +
  labs(x = "",
       y = "", title = 'IC da Diferença Bfs - Epsilon-greedy') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.dif.preci.greedy.bfs, p2.dif.preci.greedy.bfs, nrow = 1)

```

Sob a pespectiva dos valores de Recall e Precisão, é observado apenas uma discreta variância de 0.01 entre os algoritmos de busca.  Falar sobre o motivo  


### IC 


```{r eval=FALSE, include=FALSE}

#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

f1_score_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$f1_score)
    ))
}

create_ic.mun <- function(x, y) {
  x <- last(x)
  y <- last(y)
  
  df.boot.mun <- filter(metricas_result_exp01, aproach == x, municipio == y)
  
  bootstrap.aproach.mun <- boot(
          data = df.boot.mun, 
          statistic = f1_score_boot, 
          R = 4000 )
  
  print(glimpse(bootstrap.aproach.mun))

  
  ci = tidy(bootstrap.aproach.mun, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


boot.aproach_exp01.mun <- metricas_result_exp01 %>%
  group_by(aproach, municipio) %>% 
  summarise(
     median_value = median(f1_score),
     ci = create_ic.mun(aproach, municipio)
  ) %>% 
  unnest(ci)

  
boot.aproach_exp01.mun %>% 
  ggplot() + 
  geom_errorbar(aes(x = municipio, y = statistic, ymin = conf.low, ymax = conf.high), width = 0.05) +
  geom_point(aes(x=municipio, y=median_value), color='red', size=1) +
  coord_flip() +
  facet_grid(. ~aproach) 
  

```



```{r echo=FALSE}
metricas_result_exp01 %>%
  group_by(aproach)  %>%
  ggplot(aes(x = reorder(aproach, +(median_num_access_node)), y = median_num_access_node)) + 
  geom_dotplot(aes(fill = aproach),
               color='white',
               binaxis = "y", 
               binwidth = 3,
               stackdir = "center") +
  stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,
                 geom = "crossbar", width = 0.3, alpha=0.3,aes(colour='Mediana'), ) +
  scale_linetype_manual("", values=c("median"="x")) +
  scale_fill_manual(values=c("#999999", "#f39422", "#537ec5", '#293a80')) +
  scale_colour_manual(values=c("black", "black", "#56B4E9", '#293a80')) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "") + 
  guides(fill=guide_legend(title="Algoritmo")) + 
  theme(legend.position = "top")

ggsave('exp01-n-access-nodes.png')
```


### Intervalos de confiança para Número de Nós acessados 


```{r echo=FALSE}
#Calcula a media das posições escolhidas nas buscas.
set.seed(123)

median_num_access_node_boot <- function (d, i) {
    dt<-d[i,]
    return(c(
          median(dt$median_num_access_node)
    ))
}

create_ic_median_num_access_node <- function(x) {
  x <- last(x)
  df.boot <- filter(metricas_result_exp01, aproach == x)
  
  bootstrap.aproach.median_num_access_node <- boot(
          data = df.boot, 
          statistic = median_num_access_node_boot, 
          R = 4000 )
  
  ci = tidy(bootstrap.aproach.median_num_access_node, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)
  
  print(glimpse(ci))
  
  return(ci)
}


ics.aproach_exp01.median_num_access_node <- metricas_result_exp01 %>%
  group_by(aproach) %>% 
   summarise(
     median_value = median(median_num_access_node),
     ci = list(create_ic_median_num_access_node(aproach))
  ) %>% 
  unnest(ci) 

```

#### IC Diferença Mediana do Número de nós do Bfs e Epsilon-greedy


```{r echo=FALSE}

diff_median_num_access.e_greedy.bfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(median_num_access_node))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  
  return(bfs-e_greedy)
}

booted.dif.median_num_access.bfs.e_greedy <- boot(data = metricas_result_exp01, 
               statistic = diff_median_num_access.e_greedy.bfs, 
               R = 4000)

ci.dif.median_num_access.bfs.e_greedy.greedy = tidy(booted.dif.median_num_access.bfs.e_greedy, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.median_num_access.bfs.e_greedy.greedy)

p1.dif.median_num_access.bfs.e_greedy= ics.aproach_exp01.median_num_access_node %>% 
  filter(aproach != 'Dfs') %>%  
 ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(8, 30) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.median_num_access.greedy.bfs = ci.dif.median_num_access.bfs.e_greedy.greedy %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-8, 8)) +
  labs(x = "",
       y = "", title = 'Diferença') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.dif.median_num_access.bfs.e_greedy, p2.dif.median_num_access.greedy.bfs, nrow = 1)

```

#### IC Diferença Mediana do Número de nós do dfs e Epsilon-greedy


```{r echo=FALSE}

diff_median_num_access.e_greedy.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(median_num_access_node))
  
  e_greedy = grupo %>% filter(aproach ==  "Epsilon-greedy") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(e_greedy-dfs)
}

booted.dif.median_num_access.dfs.e_greedy <- boot(data = metricas_result_exp01, 
               statistic = diff_median_num_access.e_greedy.dfs, 
               R = 4000)

ci.dif.median_num_access.dfs.e_greedy.greedy = tidy(booted.dif.median_num_access.dfs.e_greedy, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.median_num_access.dfs.e_greedy.greedy)

p1.dif.median_num_access.dfs.e_greedy= ics.aproach_exp01.median_num_access_node %>% 
  filter(aproach != 'Bfs') %>%  
 ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(8, 30) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.median_num_access.greedy.dfs = ci.dif.median_num_access.dfs.e_greedy.greedy %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-8, 8)) +
  labs(x = "",
       y = "", title = 'Diferença') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.dif.median_num_access.dfs.e_greedy, p2.dif.median_num_access.greedy.dfs, nrow = 1)

```

#### IC Diferença Mediana do Número de nós do dfs e Epsilon-greedy


```{r echo=FALSE}

diff_median_num_access.bfs.dfs <- function (d, i) {

  grupo = metricas_result_exp01 %>% 
    slice(i) %>% 
    group_by(aproach) %>% 
    summarise(median_value_test = median(median_num_access_node))
  
  bfs = grupo %>% filter(aproach ==  "Bfs") %>% pull(median_value_test)
  dfs = grupo %>% filter(aproach ==  "Dfs") %>% pull(median_value_test)
  
  return(bfs-dfs)
}

booted.dif.median_num_access.dfs.bfs <- boot(data = metricas_result_exp01, 
               statistic = diff_median_num_access.bfs.dfs, 
               R = 4000)

ci.dif.median_num_access.dfs.bfs = tidy(booted.dif.median_num_access.dfs.bfs, 
          conf.level = .95,
          conf.method = "bca",
          conf.int = TRUE)

glimpse(ci.dif.median_num_access.dfs.bfs)

p1.dif.median_num_access.dfs.bfs = ics.aproach_exp01.median_num_access_node %>% 
  filter(aproach != 'Epsilon-greedy') %>%  
 ggplot(aes(x = aproach, y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  ylim(8, 30) +
  labs(x='Algoritmo', y="Número de Nós Acessados", title="", color = "")  +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  coord_flip() 
  

p2.dif.median_num_access.bfs.dfs = ci.dif.median_num_access.dfs.bfs %>% 
  ggplot(aes(x = "", y = statistic,
             ymin = conf.low,
             ymax = conf.high)) +
  geom_pointrange() +
  geom_point(size = 2) + 
  coord_flip(ylim = c(-8, 8)) +
  labs(x = "",
       y = "", title = 'Diferença') +
  theme_minimal() +
  theme(plot.title = element_text(hjust = .5), plot.subtitle = element_text(hjust = .5, color = "gray40")) +
  geom_hline(yintercept = 0, color="#B2B0AF",)


grid.arrange(p1.dif.median_num_access.dfs.bfs, p2.dif.median_num_access.bfs.dfs, nrow = 1)

```

## F1 Score por cada Município da Amostra 


```{r echo=FALSE}
metricas_result_exp01 %>% 
  group_by(municipio, aproach) %>% 
  summarise(max_value = max(f1_score), min_value = min(f1_score), median_value=median(f1_score)) %>% 
  ggplot(aes(y=municipio)) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=2,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=2, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='F1 Score', y=NULL, title="") +
  facet_grid(.~ aproach)  + 
  theme(legend.position = "top")

ggsave('exp01-f1score-by_municipios.png')

```

## f1 Score por combinação

```{r echo=FALSE}

metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(f1_score), min_value = min(f1_score), median_value=median(f1_score), dif = max_value - min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='F1 Score', y=NULL, title="") +
  facet_grid(.~ aproach)  + 
  theme(legend.position = "top")

ggsave('exp01-f1score-by_combinations.png')

```

## Número de nós acessados por combinação

```{r echo=FALSE}

metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(max_num_access_node), min_value = min(max_num_access_node), median_value=median(max_num_access_node), dif = max_value-min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='Número de Nós Acessados', y=NULL, title="") +
  facet_grid(.~ aproach) + 
  theme(legend.position = "top")

ggsave('exp01-num_nodes_by_combinations.png')

```

## Duração das avaliações por combinações

```{r echo=FALSE}
metricas_result_exp01 %>% 
  group_by(combination, aproach) %>% 
  summarise(max_value = max(max_durationMin), min_value = min(max_durationMin), median_value=median(max_durationMin), dif = max_value - min_value) %>% 
  ggplot(aes(y=reorder(combination, dif))) + 
  geom_point(aes(x=min_value, color='#293a80'), size=1, shape=108) +
  geom_point(aes(x= max_value, color='#537ec5'), size=1, shape=108)  +
  geom_dumbbell(color="#e3e2e1", aes(x = min_value, xend = max_value), colour_x = "#293a80", colour_xend = "#537ec5", size=3.1,
                dot_guide=TRUE, dot_guide_size=0.25, shape=108) + 
  #geom_point(aes(x= median_value, color='#f39422'), size=6, shape=108) +
  geom_point(aes(x= median_value, color='#f39422'), size=3, alpha= 0.8, shape=108) +
  scale_color_manual(name = "", values = c("#293a80", "#537ec5", "#f39422"), labels = c("Mínimo", "Máximo", "Mediana")) +
  labs(x='Duração (Min)', y=NULL, title="") +
  facet_grid(.~ aproach) + 
  theme(legend.position = "top")

ggsave('exp01-duration_nodes_by_combinations.png')

```

## Número de Avaliações por abordagem

```{r echo=FALSE}
metricas_result_exp01 %>%
    group_by(municipio) %>%
    summarise(bfs = sum(aproach == 'Bfs'), dfs = sum(aproach == 'Dfs'), bandit = sum(aproach == 'Epsilon-greedy')) %>%
    arrange(desc(dfs)) %>%
    datatable(options = list(pageLength = 10),  rownames = FALSE, class = 'cell-border stripe')
```

## Todas as Avaliações

```{r echo=FALSE}
metricas_result_exp01 %>%
    select(municipio, aproach, date, recall, precision, f1_score) %>%
    arrange(desc(recall)) %>% 
    datatable(options = list(pageLength = 10),  rownames = FALSE, class = 'cell-border stripe')
```

